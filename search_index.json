[
["index.html", "About this Guide", " About this Guide Houston R Users are hosting a guided intro workshop on November 12, 2016. This guide is the full version of the short guide handed out at the workshop. This is a reference for reviewing things we covered in person, or for a self-guided introduction to R. "],
["welcome-to-intro-to-r.html", "1 Welcome to Intro to R 1.1 Why R? 1.2 When to use R? 1.3 What is the scope of this workshop?", " 1 Welcome to Intro to R We are very excited you could make it to this Intro to R workshop! We hope to leave this workshop with some practical practice under our belts working with data in R and the ability to find and understand resources when applying these steps to our own datasets. 1.1 Why R? R is a programming language designed specifically for statistics. Because it is a free and open source language, many people have contributed to the R ecosystem. In addition to being very powerful and expressive for statistical analysis, R has become very popular for doing exploratory data visualization and reporting as well. 1.2 When to use R? R is limited in producing highly-customized and interactive reporting visualizations While R is able to produce interactive graphics, maps, and dashboards, a lot of the more expressive and customized interactive data presentations will require knowledge of JavaScript. The amount you can do directly from within R is increasing rapidly, however, and you can read more about that here. R is not as expressive for general tasks such as scraping and crawling New additions to R like tidyr and dplyr are making R more expressive; the result is R is becoming a strong competitor in more general tasks like data-mining, data-wrangling, and scraping and crawling for data. R requires data to be loaded into memory For projects where exceptionally large data needs to be analyzed or processed very quickly, we will want to consider using tools that help us work around the memory limitations. Overall, R is a top choice for data exploration, modelling, analysis, and static graphics. 1.3 What is the scope of this workshop? This workshop will cover steps and code that can be readily adapted for small to moderate sized datasets. Specifically, we will be: Loading in data Exploring it Cleaning it Calculating descriptive statistics Visualizing it Modeling it Making a report We will also cover how to get help and how to learn more about using R. Additionally, we’ve pulled together different resources for things we aren’t covering into our appendix. While we will not be able to cover how to handle a wide variety of different datasets and visualizations, our mentors have a wide range of experiences with using R for energy data, bioinformatics, mapping, natural language processing, and much more! We hope to get to know you throughout the workshop and share domain specific experiences with you. "],
["interacting-with-simple-data.html", "2 Interacting with Simple Data 2.1 What is RStudio? 2.2 Coding in the console 2.3 Loading in data 2.4 Glancing at the data 2.5 Visualizing the data 2.6 Modeling the data 2.7 Working with a simple dataset", " 2 Interacting with Simple Data 2.1 What is RStudio? Today, we will be working with R in RStudio. While there are other programs we can use to write R, RStudio has become the standard environment for working with R. RStudio has four main windows: a file viewer, an interactive console, an environment viewer, and directory viewer. Let’s focus on the interactive console first. 2.2 Coding in the console Click in the interactive console. You’ll notice a cursor will start blinking next to the &gt; symbol. This is called the command prompt; the computer is waiting for us to give it a command; it’s “prompting” us, and letting us know it’s ready. Given that R was made for statistics, we should expect it to have no problems with numbers and math. Let’s try some basics! 1 ## [1] 1 1 + 5 ## [1] 6 10 + 12 ## [1] 22 Pressing enter after each line of code runs it, and R will tell us the answer right away. This lets us interact with R quickly. R, like other programming languages, can remember information we give it in named variables. This is called assigning variables with a value. Let’s tell R to remember some information for us. x &lt;- 1 y &lt;- 5 z &lt;- 10 The &lt; and - can be seen as an arrow pointing to the left. You can think of this as saying, “assign the value 1 to a variable named x”. If you are familiar with other programming languages, &lt;- and = can be used interchangably in R, but the preferred way is to use &lt;-. We can also see all the information we’ve told R to remember in the environment viewer. We can ask R what the values of these variables are: x ## [1] 1 y ## [1] 5 z ## [1] 10 We can also use these variables like so: x + y ## [1] 6 x + z ## [1] 11 z * y ## [1] 50 And if we try to ask R about a variable it doesn’t know about, R will tell us that it can’t find that variable: a ## Error in eval(expr, envir, enclos): object &#39;a&#39; not found This is neat and all, but we’re here to dig into data, so let’s get to it! 2.3 Loading in data We are going to load in CSV files today to get data into R. R is powerful for statistics because it has a great base collection of functions, or named procedures, for common things we’d want to do with data, like reading in a CSV. R’s base way of doing this is with a function named read.csv. Like the named variables, we can get what read.csv is by referring to its name. For more info on loading data, see here. read.csv ## function (file, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;, ## fill = TRUE, comment.char = &quot;&quot;, ...) ## read.table(file = file, header = header, sep = sep, quote = quote, ## dec = dec, fill = fill, comment.char = comment.char, ...) ## &lt;bytecode: 0x28cfa08&gt; ## &lt;environment: namespace:utils&gt; Here, we get back just what read.csv is. In order to tell R to do or run the function, we need to run: read.csv() ## Error in read.table(file = file, header = header, sep = sep, quote = quote, : argument &quot;file&quot; is missing, with no default To learn more about any function, we can add a ? in front of the function name like this: ?read.csv In order to know what file to read in, we need to give the function the location of the file: read.csv(file = &#39;crickets.csv&#39;) ## Chirpspersecond Temperature ## 1 20.0 88.6 ## 2 16.0 71.6 ## 3 19.8 93.3 ## 4 18.4 84.3 ## 5 17.1 80.6 ## 6 15.5 75.2 ## 7 14.7 69.7 ## 8 17.1 82.0 ## 9 15.4 69.4 ## 10 16.2 83.3 ## 11 15.0 79.6 ## 12 17.2 82.6 ## 13 16.0 80.6 ## 14 17.0 83.5 ## 15 14.4 76.3 RStudio reminds us what different functions are named as we start typing them into console, and reminds us what additional information each of those functions may need when we type the (. It also automatically completes the function call for us with the ). When we read in the CSV, R printed the data out to us. In order to really use the data though, we need to tell R to remember the data by assigning it to a variable. We want to name our variables so that they’re easy to remember and indicative of what information they are holding onto. crickets &lt;- read.csv(file = &#39;crickets.csv&#39;) Now, when we ask R about crickets, we get the data back! crickets ## Chirpspersecond Temperature ## 1 20.0 88.6 ## 2 16.0 71.6 ## 3 19.8 93.3 ## 4 18.4 84.3 ## 5 17.1 80.6 ## 6 15.5 75.2 ## 7 14.7 69.7 ## 8 17.1 82.0 ## 9 15.4 69.4 ## 10 16.2 83.3 ## 11 15.0 79.6 ## 12 17.2 82.6 ## 13 16.0 80.6 ## 14 17.0 83.5 ## 15 14.4 76.3 There are many other ways to load in data from other file types. Googling “read xls to R” will give us some great answers on how to read in data as an Excel sheet. We also have a quick list of standard ways to load other common file types in the appendix. Let’s get a quick sense of what this data is like! 2.4 Glancing at the data Here’s a table of some quick functions we can run on the data to learn about it: Code Description names(crickets) Column header names dim(crickets) Number of rows by number of columns nrow(crickets) Number of rows ncol(crickets) Number of columns str(crickets) Structure of data summary(crickets) Summary of the data View(crickets) View data in file viewer We can also look at parts of the data using verbs like filter() and select(), provided by the dplyr package. install.packages(&#39;dplyr&#39;) library(dplyr) We can look at just specific rows matching a certain condition, using filter(): filter(crickets, Temperature &lt; 75) ## Chirpspersecond Temperature ## 1 16.0 71.6 ## 2 14.7 69.7 ## 3 15.4 69.4 filter(crickets, Temperature == 82) ## Chirpspersecond Temperature ## 1 17.1 82 or just specific columns, using select(): select(crickets, Chirpspersecond) ## Chirpspersecond ## 1 20.0 ## 2 16.0 ## 3 19.8 ## 4 18.4 ## 5 17.1 ## 6 15.5 ## 7 14.7 ## 8 17.1 ## 9 15.4 ## 10 16.2 ## 11 15.0 ## 12 17.2 ## 13 16.0 ## 14 17.0 ## 15 14.4 select(crickets, Temperature) ## Temperature ## 1 88.6 ## 2 71.6 ## 3 93.3 ## 4 84.3 ## 5 80.6 ## 6 75.2 ## 7 69.7 ## 8 82.0 ## 9 69.4 ## 10 83.3 ## 11 79.6 ## 12 82.6 ## 13 80.6 ## 14 83.5 ## 15 76.3 We can pass the output of one of these to another function to calculate the mean. mean(unlist(select(crickets, Temperature))) ## [1] 80.04 Notice how we nested one function inside another? There’s another way to do this, a way that’s more readable and easier to reason about. We can use the pipe operator, represented by the %&gt;% symbol, to achieve the same thing. crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% mean() ## [1] 80.04 You read this left to right, and you can see the steps the data go through in logical order. We can use this approach to calculate our own means, standard deviations, and medians: crickets %&gt;% select(Chirpspersecond) %&gt;% unlist() %&gt;% median() crickets %&gt;% select(Chirpspersecond) %&gt;% unlist() %&gt;% sd() crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% mean() crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% median() crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% sd() We can also ask R for the max and the min values: crickets %&gt;% select(Chirpspersecond) %&gt;% unlist() %&gt;% max() crickets %&gt;% select(Chirpspersecond) %&gt;% unlist() %&gt;% min() crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% max() crickets %&gt;% select(Temperature) %&gt;% unlist() %&gt;% min() There’s many more calculations we can run on the data, but plotting the data will help us we a better picture of it. 2.5 Visualizing the data Base R can plot our data, but the wonderful thing about R being open-sourced is that it’s encouraged many people to expand it’s functionality by writing groups of functions, called packages. These packages are available for everyone to install and use. To plot our data, we will use an outside package, called ggplot2, which has become the standard way to plot data in R. We can install the ggplot2 package by calling the install.packages function like this: install.packages(&#39;ggplot2&#39;) While the package is installing, let’s take a break! Once the package installed, we need to tell R to load it so we can use it. library(ggplot2) To start, we can tell ggplot what our data is: ggplot(data = crickets) This gives us back a rather boring blank gray square. At this point, ggplot does not know what about the data to map to where. We can tell it to map Temperature as the x and Chirpspersecond as the y, like this: ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) At this point, ggplot seems to know where things should go, but there’s no points. This base layer is ready with our coordinates and axis, but we would also like ggplot to map the data in the same way to a layer of markings that represent the data. Let’s try points: ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) + geom_point() We now have points, each with its y mapped to Chirpspersecond and the x mapped to Temperature. We can also mapped the color of each point to the temperature like this: ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) + geom_point(mapping = aes(color = Temperature)) This gives the points colors mapped from the Temperature along a default scale. We can adjust the scale to give a sense of the temperature like this: ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) + geom_point(mapping = aes(color = Temperature)) + scale_color_gradient(low = &quot;orange&quot;, high = &quot;red&quot;) Let’s take some time to experiment with different visualizations using ggplot2. See the data visualization cheat sheet for ideas. One of the reasons that ggplot is so popular is that it has a very extensible syntax. ggplot is built on the concept of a grammar of graphics. The grammar of graphics is a way to build plots in a structured way. Every plot consists of a dataset, aesthetics to map of the dataset, and a geom that defines how to display the data. Let’s break down our function call above into its graphical grammar elements: dataset = the crickets data frame aesthetics = the Temperature and Chirpspersecond variables geom = the point geom (geom_point function call) is used to create a scatterplot The syntax may seem a little confusing at first, but it can create some very powerful results once you understand how it works. It allows you to build up plots in layers. It also allows you to manipulate plots in a way similar to manipulating data (via function calls). For example, we can assign our plot to a variable p. p &lt;- ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) + geom_point(mapping = aes(color = Temperature)) + scale_color_gradient(low = &quot;orange&quot;, high = &quot;red&quot;) p Now we can manipulate our plot like any other variable. Let’s add a title. p + ggtitle(&quot;Cricket Chirps vs. Temperature&quot;) We can also add another geom just as easily. Let’s add a smoothing function to show what a linear model might look like. p + ggtitle(&quot;Cricket Chirps vs. Temperature&quot;) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; Once we have a plot we like, we can save our last plot to an image file very easily: ggsave(filename = &quot;plot.png&quot;) ## Saving 7 x 5 in image ## `geom_smooth()` using method = &#39;loess&#39; 2.6 Modeling the data From the plots, we see a potential correlation between Chirpspersecond and Temperature. If we were ever without our smart phones and thermometers, out in the country with some crickets, we might want to know if we can use the Chirpspersecond to calculate the Temperature. We can calculate the linear model for Temperature vs. Chirpspersecond using R’s lm function: lm(Temperature ~ Chirpspersecond, data = crickets) ## ## Call: ## lm(formula = Temperature ~ Chirpspersecond, data = crickets) ## ## Coefficients: ## (Intercept) Chirpspersecond ## 25.232 3.291 To calculate a linear model for Chirpspersecond from Temperature, we would do this: lm(Chirpspersecond ~ Temperature, data = crickets) ## ## Call: ## lm(formula = Chirpspersecond ~ Temperature, data = crickets) ## ## Coefficients: ## (Intercept) Temperature ## -0.3091 0.2119 There’s actually more information that lm tells us. Let’s take a look by first telling the computer the remember the result as a variable called crickets_lm. crickets_lm &lt;- lm(Chirpspersecond ~ Temperature, data = crickets) We can use the broom package to help us get to the information stored in the model. Let’s install that first: install.packages(&#39;broom&#39;) library(&#39;broom&#39;) For example: tidy(crickets_lm) ## term estimate std.error statistic p.value ## 1 (Intercept) -0.3091419 3.10858391 -0.09944782 0.9222999135 ## 2 Temperature 0.2119250 0.03871123 5.47450961 0.0001066719 We get the slope and the intercept from the estimate column. Let’s use tidy() and geom_abline() to add a line on top of our scatterplot so we can eyeball how our linear model fits. lm_intercept &lt;- crickets_lm %&gt;% tidy %&gt;% filter(term == &quot;(Intercept)&quot;) %&gt;% select(estimate) %&gt;% unlist() lm_slope &lt;- crickets_lm %&gt;% tidy %&gt;% filter(term == &quot;Temperature&quot;) %&gt;% select(estimate) %&gt;% unlist() ggplot(data = crickets, mapping = aes(x = Temperature, y = Chirpspersecond)) + geom_point(mapping = aes(color = Temperature)) + scale_color_gradient(low = &quot;orange&quot;, high = &quot;red&quot;) + geom_abline(slope = lm_slope, intercept = lm_intercept, color = &quot;maroon&quot;) Additionally, cor and cor.test are two functions that can tell us about correlations between paired samples. As before, the ? can help us learn more: ?cor ?cor.test We can run these functions on our data by using crickets[,1] as the x, and crickets[,2] as the y like so: cor(x = crickets[,1], y = crickets[,2]) ## [1] 0.8351438 cor.test(x = crickets[,1], y = crickets[,2]) ## ## Pearson&#39;s product-moment correlation ## ## data: crickets[, 1] and crickets[, 2] ## t = 5.4745, df = 13, p-value = 0.0001067 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5642928 0.9436856 ## sample estimates: ## cor ## 0.8351438 2.7 Working with a simple dataset So far, we’ve: Loaded in the data from a csv crickets &lt;- read.csv(file = &#39;crickets.csv&#39;) Learned more about the data as a whole Code Description names(crickets) Column header names dim(crickets) Number of rows by number of columns nrow(crickets) Number of rows ncol(crickets) Number of columns str(crickets) Structure of data summary(crickets) Summary of the data View(crickets) View data in file viewer Looked at the data by rows and columns Code Description filter(crickets, Temperature &lt; 85 Rows with temperature less than 80 filter(crickets, Chirpspersecond &gt; 15 Rows with chirps per second greater than 15 select(crickets, Chirpspersecond) First column, Chirpspersecond select(crickets, Temperature) Second column, Temperature Calculated descriptive statistics on the data Code Description mean() Average Temperature median() Median Temperature sd() Standard deviation of Temperature max() Maximum Temperature min() Minimum Temperature Made plots of our data Code Description ggplot() create base layer of plot geom_point() scatterplot geom geom_smooth() smoothing geom with confidence intervals geom_abline() line geom ggtitle() add title to plot Applied statistical modelling to the data Code Description cor(crickets) calculate correlation coefficient cor.test(crickets) test for statistically significant correlation lm(crickets) create a linear model Crickets is a rather small and well-formed dataset. Let’s practice our new skills on a slightly more realistic dataset and learn additional skills for cleaning the data and making a report. "],
["this-time-its-for-real.html", "3 This time it’s for real! 3.1 Loading and exploring a larger dataset 3.2 Counting missing values 3.3 Ignoring missing values 3.4 Non-numeric data 3.5 Analyzing and Visualizing the data using a script 3.6 Modeling the data 3.7 Making a reproducible report", " 3 This time it’s for real! Let’s pick up the pace and put our newfound skills to the test. For this section, we’re gonna use a dataset that looks more like what we’ll encounter in real life. It’s bigger in both dimensions; it has more rows but also more columns. It also has some missing data (oh noes!). Now things are getting real. 3.1 Loading and exploring a larger dataset We can load our new dataset the same way as before, using the read.csv() function. airquality &lt;- read.csv(&#39;airquality.csv&#39;) We can also load our dataset from an Excel file using the openxlsx package. install.packages(&#39;openxlsx&#39;) library(openxlsx) airquality &lt;- read.xlsx(&#39;airquality.xlsx&#39;) Let’s take a moment to explore the new dataset using tools we learned in the previous section. Try str, head, summary and get a good feel for the dataset. For example, we can find the number of rows using nrow. library(magrittr) # load using `library` if not already loaded airquality %&gt;% nrow() ## [1] 153 3.2 Counting missing values I mentioned this dataset has some missing data. You may have noticed it already when exploring. In R, missing values are represented by the NA symbol. It’s always a good idea to check for missing values, even if you are sure your data is complete. We can ask R to tell us whether there are any NAs in the dataset using the is.na() function. airquality %&gt;% is.na() This will list out TRUE or FALSE for every value in new_data, for the question “is this value equal to NA?”. It’s kind hard to read, though. If we wanted to get a general sense of how many NAs there were in our entire dataset, we could do something like this: airquality %&gt;% is.na() %&gt;% sum() ## [1] 44 3.3 Ignoring missing values If we try to call some descriptive statistics on any columns with NA values, we will get an ugly result. Let’s try getting the mean for Ozone levels. library(dplyr) # load using `library` if not already loaded airquality %&gt;% summarise(mean(Ozone)) ## mean(Ozone) ## 1 NA Not what we were looking for. By default, many functions in R will return NA if called on a vector with any NA values inside. We can override this behavior by adding the na.rm = TRUE argument airquality %&gt;% summarise(mean(Ozone, na.rm=TRUE)) ## mean(Ozone, na.rm = TRUE) ## 1 42.12931 There are important questions to ask yourself when dealing with missing data; there’s no one-size-fits-all answer for it. A slapdash approach is to simply remove any rows with missing data. aircomplete &lt;- airquality %&gt;% filter(complete.cases(airquality)) If you call nrow on aircomplete, you’ll see we have 111 rows now instead of the 153 we had before. aircomplete %&gt;% nrow() ## [1] 111 3.4 Non-numeric data So far, we’ve primarily worked with numeric data. Let’s talk briefly about how R handles string or character data. Here’s a data frame with some letters. myname &lt;- data.frame(letter=c(&quot;k&quot;,&quot;e&quot;,&quot;l&quot;,&quot;s&quot;,&quot;e&quot;,&quot;y&quot;)) Let’s look at the structure of the myname object, and the letter field of the object. myname %&gt;% str() ## &#39;data.frame&#39;: 6 obs. of 1 variable: ## $ letter: Factor w/ 5 levels &quot;e&quot;,&quot;k&quot;,&quot;l&quot;,&quot;s&quot;,..: 2 1 3 4 1 5 myname$letter %&gt;% str() ## Factor w/ 5 levels &quot;e&quot;,&quot;k&quot;,&quot;l&quot;,&quot;s&quot;,..: 2 1 3 4 1 5 Hmm, it says Factor w/ 5 levels &quot;e&quot;,&quot;k&quot;,&quot;l&quot;,&quot;s&quot;,..: 2 1 3 4 1 5. What does this mean? By default, R stores string fields in data frames as factors. Behind the scenes, R identifies the unique character strings in the field, substitutes each one with a unique integer, and remembers the original strings as levels. myname$letter %&gt;% levels() ## [1] &quot;e&quot; &quot;k&quot; &quot;l&quot; &quot;s&quot; &quot;y&quot; myname$letter %&gt;% as.integer() ## [1] 2 1 3 4 1 5 For many processes and analyses, this data structure will work fine. In some situations, however, it becomes problematic. Let’s try to modify the myname data frame, and make the letters spell out kelsie rather than kelsey. We need to change the letter in the 6th position to e and the letter in the 5th position to i. myname$letter[6] &lt;- &quot;e&quot; myname$letter[5] &lt;- &quot;i&quot; ## Warning in `[&lt;-.factor`(`*tmp*`, 5, value = structure(c(2L, 1L, 3L, 4L, : ## invalid factor level, NA generated Let’s print the updated data frame. Not what we want. There are a couple of ways to override R’s default behavior of storing text fields as columns. If we’re creating a data frame from scratch, we can set the stringsAsFactors parameter equal to FALSE. myname &lt;- data.frame(letter=c(&quot;k&quot;,&quot;e&quot;,&quot;l&quot;,&quot;s&quot;,&quot;e&quot;,&quot;y&quot;), stringsAsFactors=FALSE) Check out the structure str and see what is different. Let’s try making the same modifications now. myname$letter[6] &lt;- &quot;e&quot; myname$letter[5] &lt;- &quot;i&quot; The character data type is much more flexible. If we’ve already created (or read) a data frame, we can use the as.character function on the text field itself. myname &lt;- data.frame(letter=c(&quot;k&quot;,&quot;e&quot;,&quot;l&quot;,&quot;s&quot;,&quot;e&quot;,&quot;y&quot;)) myname %&gt;% str() ## &#39;data.frame&#39;: 6 obs. of 1 variable: ## $ letter: Factor w/ 5 levels &quot;e&quot;,&quot;k&quot;,&quot;l&quot;,&quot;s&quot;,..: 2 1 3 4 1 5 myname$letter &lt;- myname$letter %&gt;% as.character() myname %&gt;% str() ## &#39;data.frame&#39;: 6 obs. of 1 variable: ## $ letter: chr &quot;k&quot; &quot;e&quot; &quot;l&quot; &quot;s&quot; ... myname$letter[6] &lt;- &quot;e&quot; myname$letter[5] &lt;- &quot;i&quot; Looking out for factors is critical when typecasting numeric data that is mistakenly stored as text. Here’s another data frame. fives &lt;- data.frame(v1=c(&quot;5&quot;,&quot;10&quot;,&quot;15&quot;,&quot;20&quot;)) Let’s look at the structure and levels: fives %&gt;% str() ## &#39;data.frame&#39;: 4 obs. of 1 variable: ## $ v1: Factor w/ 4 levels &quot;10&quot;,&quot;15&quot;,&quot;20&quot;,..: 4 1 2 3 fives$v1 %&gt;% levels() ## [1] &quot;10&quot; &quot;15&quot; &quot;20&quot; &quot;5&quot; We want these data points stored as a numeric type, but currently, they’re stored as text, and specifically as a factor. What does it look like if we convert the factor to numeric? fives$v1 %&gt;% as.numeric() ## [1] 4 1 2 3 So problematic! Why did this happen? fives$v1 %&gt;% as.character() %&gt;% as.numeric() ## [1] 5 10 15 20 That works as expected. Are factors ever useful? Yes. Here’s some pretend survey data. survey &lt;- data.frame(gender=rep(c(&quot;Male&quot;, &quot;Female&quot;), c(5, 7)), response=rep(c(&quot;Excellent&quot;, &quot;Good&quot;, &quot;Fair&quot;, &quot;Poor&quot;), 3)) Let’s change the levels of the gender field. survey$gender %&gt;% levels() ## [1] &quot;Female&quot; &quot;Male&quot; levels(survey$gender) &lt;- c(&quot;F&quot;,&quot;M&quot;) What does it look like now? We can also take advantage of our understanding of the factor data type to convert the response variable into a numeric field. I want excellent to map to 4, good to map to 3, fair to map to 2 and poor to map to 1. We’ll use the as.numeric function eventually, but first we need to see if the levels are in the order that we want them. survey$response %&gt;% levels() ## [1] &quot;Excellent&quot; &quot;Fair&quot; &quot;Good&quot; &quot;Poor&quot; They’re not. Let’s change them, so that less favorable responses will appear before more favorable responses when alphabetized. After we change the levels, we’ll need to turn the response field into a character field, and then re-factor. levels(survey$response) &lt;- c(&quot;D Excellent&quot;,&quot;B Fair&quot;,&quot;C Good&quot;,&quot;A Poor&quot;) survey$response &lt;- survey$response %&gt;% as.character() %&gt;% as.factor() survey$response %&gt;% levels() ## [1] &quot;A Poor&quot; &quot;B Fair&quot; &quot;C Good&quot; &quot;D Excellent&quot; Much better. Now we can call the as.numeric function. survey %&gt;% mutate(as.numeric(response)) ## gender response as.numeric(response) ## 1 M D Excellent 4 ## 2 M C Good 3 ## 3 M B Fair 2 ## 4 M A Poor 1 ## 5 M D Excellent 4 ## 6 F C Good 3 ## 7 F B Fair 2 ## 8 F A Poor 1 ## 9 F D Excellent 4 ## 10 F C Good 3 ## 11 F B Fair 2 ## 12 F A Poor 1 How useful! 3.4.1 The takeaway By default, R stores text fields as factors. And factors are strange. At times it seems like they are working against us. But if we understand how they work, we can make them work for us! Now, back to numeric data. 3.5 Analyzing and Visualizing the data using a script 3.5.1 Creating a R script to save code and analysis Now, I want you to go back and do everything we just did over again. What, you think that’s ridiculous? The reality is, we often have to go back and make changes upstream. When we do this, it can get very, very painful if we’re doing everything interactively, in the console. In all our previous examples we have been using the interactive console. It is an excellent application to quickly analyze the data, but we need to keep a reasonable log of what we did (and possibly way). Let us start by creating a file, with all the commands we used in a sequence. Click the symbol for New Script and you’ll see RStudio’s built-in text editor pop up. And then we will clear the session, to remove all the variables from the environment. This insures that we are starting with a clean slate. Let’s take a moment to put all our work in. I know it’s a pain but it will pay off if we want to make changes later. It is good practice, in programming to place all the libraries we need at the top. Imagine arranging all the ingredients before we start following a recipie for our dish. # load libraries library(ggplot2) library(dplyr) # read in data airquality &lt;- read.csv(&#39;airquality.csv&#39;) We can start by visualizing the data. We have more data to play with now, but let’s start with the same plot we used last time. # plot to compare temperature vs ozone p &lt;- ggplot(airquality) + geom_point(aes(x=Temp, y=Ozone)) print(p) ## Warning: Removed 37 rows containing missing values (geom_point). You’ll notice two new things about what we did here. First, we assign the output to p, this will be important when we want to make adjustments to the plot later. Second, you’ll notice when we do that, nothing appears; we have to print the p to get it to show up. Notice how we get warning messages, with NA’s, let use complete.cases function, to filter out such rows. # filter for only complete cases aircomplete &lt;- filter(airquality, complete.cases(airquality)) # create a plot comparing, Ozone levels with Temperature p &lt;- ggplot(aircomplete) + geom_point(aes(x=Temp, y=Ozone)) print(p) We can run the entire script by clicking Source at the top of the editor pane. To run just a specific line or lines, you can select the section you want to run and then click Run. Let’s get back to our data. You may have seen a pattern in the plot we made earlier. Let’s pick up our analysis with a little more visualization and some modeling. 3.6 Modeling the data We’ll model the data using the reliable lm() function again. Let’s add the following to the end of our script and source it. ozone_model &lt;- lm(Ozone ~ Temp, data = aircomplete) print(summary(ozone_model)) ## ## Call: ## lm(formula = Ozone ~ Temp, data = aircomplete) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.922 -17.459 -0.874 10.444 118.078 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -147.6461 18.7553 -7.872 2.76e-12 *** ## Temp 2.4391 0.2393 10.192 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.92 on 109 degrees of freedom ## Multiple R-squared: 0.488, Adjusted R-squared: 0.4833 ## F-statistic: 103.9 on 1 and 109 DF, p-value: &lt; 2.2e-16 Our model tells us there is a statistically significant relationship between Ozone and Temperature. If we want to add the linear model to our plot, we can use the geom_abline() function. geom_abline() takes two arguments, the intercept and slope. We can use the coef() function to extract those values from the model. Add the following lines to your script and Source it. lm_coefs = coef(ozone_model) print(lm_coefs) ## (Intercept) Temp ## -147.64607 2.43911 With that info, we’re ready to add our linear model. Add the following lines to your script and Source it. p2 &lt;- p + geom_abline(intercept = -147.64607 , slope = 2.43911) print(p2) bonus We would go a little further, and bin the temperature variable into high and low, to enable comparison with ozone levels. aircomplete = mutate(aircomplete, temp2 = ifelse(Temp &gt; 80, &quot;high&quot;, &quot;low&quot;)) Next, let us create a box plot using this new temp2 variable. We would use geom_boxplot from ggplot2 to create this plot. ggplot(aircomplete) + geom_boxplot(aes(x=temp2, y=Ozone)) We see that low shows up after high on the x axis, and it is counter intuitive. This is because temp2 is a character, and ggplot2 sorts this variable alphabetically (h of high orders before l of low). So we can use factors, as explained in the previous section to switch their position. aircomplete = mutate(aircomplete, temp_fac = factor(temp2, levels = c(&quot;low&quot;, &quot;high&quot;))) We are using mutate from dplyr to add a new column temp_fac; which is a factor version of temp2. Also, you will notice we have explicitly specified the levels in a order we would like (low and high). Alright! Now lets see how temp_fac, comes to use in our boxplot. ggplot(aircomplete) + geom_boxplot(aes(x=temp_fac, y=Ozone)) 3.7 Making a reproducible report Great. Now, what if we want to make a report of our work? With R, you get the power of knitr, which will knit your work together into a report. Let’s try it on our current script. Go to File -&gt; Knit Document, name the file airquality_report and select HTML, then watch the magic happen! Here is a link to an example script: example_script.R example_script.html R basically convert the R script into markdown, and then into HTML. So have have the option of including some additional markdown instructions in this set. We need just to prefix all lines with a #' to use markdown Here are a set of a few markdown examples. "],
["time-to-explore.html", "4 Time to explore!", " 4 Time to explore! Now that you’re equipped with a number of tools, try your hand at this dataset from the Titanic. This dataset contains passenger data including name, sex, age, cabin. See if you can predict passenger’s survival based on the given information! Here is a link to more information. https://www.kaggle.com/c/titanic/data "],
["learning-more.html", "5 Learning More 5.1 Next Steps", " 5 Learning More There are many ways to continue learning R. No matter what you choose to be your next step, we’re here and eager to share experiences and questions! Join us in person for our Houston R UseRs Meetups or online in our Slack chat anytime. 5.1 Next Steps The following resources are great next steps to take for learning more on using R after this workshop. 5.1.1 R Basics To further explore basics of R, following are good resources to begin with - A good blog offering tutorials of each R function/package. Platform for R users to connect Learn R and data science interactively An Intermediate R course in 4 weeks Curated guide to learning R and its extensions 5.1.2 R for Data Science These resources are good to use R as a data science/statistics tool - R Cookbook, R Graphics Cookbook - Excellent resources for learning base R and base plotting. Contains code snippets. Available online. R for Data Science - This book penned by Hadley Wickham and Garrett Grolemund covers modern standards on using R for data science with a cohesive and conversational narrative. For a great overview of what’s in the book, check out this page Advanced R - Master R as a programming language. Also available online. ggplot2 - Learn how to create elegant graphics for data analysis 5.1.3 Practice and Learn Data Science Once you have learnt R, try your coding skills on analyzing a collection of public datasets. Kaggle Titantic examples - Learn how to tackle a machine learning problem and participate in competetions Gettings started in R Exploring Survival on the Titanic Houston data jams Attend data visualization meetups in Houston. Quick-R A collection of tutorials on how to do various things in R drivendata Like Kaggle, with a focus on good will and non-profits Data Camp Full online, interactive curriculum, some free, some not Others resources to check R by example, R Examples 5.1.4 Getting Help Houston R UseRs Slack and Meetup Cross Validated Stack Overflow 5.1.5 Staying up to date RWeekly Awesome-R "],
["installation-instructions.html", "6 Installation Instructions 6.1 R for Mac OS X 6.2 R for Windows/Linux 6.3 R Studio", " 6 Installation Instructions 6.1 R for Mac OS X 6.1.1 Option 1: CRAN Go to http://cran.us.r-project.org/ Click on “Download R for Mac OS X” Choose appropriate “R-x.x.x.pkg” based on your operating system version (“R-3.3.2.pkg” is the most recent) Follow installation instructions 6.1.2 Option 2: Homebrew If you are not sure if you have Homebrew, open your Terminal or CLI and type which brew. If you get output like this: /usr/local/bin/brew, then you have Homebrew and you are good to go. Otherwise, if you get: command not found, you’ll need to install it from here: http://brew.sh/. After confirming you have Homebrew, proceed with instructions: Open Terminal. Before installing anything, run brew update &amp;&amp; brew upgrade Copy/paste the comands below to install R: $ brew tap caskroom/cask $ brew install homebrew/completions/brew-cask-completion $ brew install Caskroom/cask/xquartz $ brew cask install java $ brew tap homebrew/science $ brew install R 6.2 R for Windows/Linux 6.2.1 Windows Go to http://cran.us.r-project.org/ Click on “Download R for Windows” &gt; “base” Install R. Leave all default settings in installation options. 6.2.2 Linux Go to http://cran.us.r-project.org/ Click on “Download R for Linux” Choose appropriate directory for your linux operating system Follow R installation instructions 6.3 R Studio Download from https://www.rstudio.com/products/rstudio/download/preview/ Select appropriate installer listed under “Desktop Version” Follow installation instructions "],
["appendix.html", "7 Appendix 7.1 Webscraping and text analysis 7.2 Machine Learning in R 7.3 Interactive R Graphics 7.4 Maps 7.5 Handling more data 7.6 General", " 7 Appendix 7.1 Webscraping and text analysis Webscraping and text analysis R-Bloggers search for web scraping A tutorial using Super Bowl Data Scraping with rvest Scraping with Selenium 7.2 Machine Learning in R Deep learning Machine learning in R R for Machine Learning notes R Machine Learning Group on Reddit 7.3 Interactive R Graphics Interactive visualizations with R “A minireview of R packages ggvis, rCharts, plotly and googleVis for interactive visualizations” Shiny Tutorial Plotly ggplot Flex Dashboard 7.4 Maps Leaflet for R Intro to making interactive maps in R Spatial Data with R Making Maps with R R-Bloggers search for maps 7.5 Handling more data Handling large data sets in R A quick tutorial Best practices for storing and using data frames too large for memory 11 tips 5 strategies 7.6 General Task Views Data Structures "]
]
